{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMNbl4T4xP9M7xTANEzqQeO"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "wk9xN--V6wQ_"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dict(data):\n",
        "  words = sorted(list(set(data)))\n",
        "  n = len(words)\n",
        "  idx = 0\n",
        "  word2Ind = {}\n",
        "  Ind2word = {}\n",
        "  for k in words:\n",
        "    word2Ind[k] = idx\n",
        "    Ind2word[idx] = k\n",
        "    idx += 1\n",
        "  return word2Ind, Ind2word"
      ],
      "metadata": {
        "id": "EntnO0Vg9QzL"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Forward propagation"
      ],
      "metadata": {
        "id": "NHYFOsTrHChE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the size of word embedding vectors\n",
        "N = 3\n",
        "\n",
        "# Define the size of vocabulary\n",
        "V = 5"
      ],
      "metadata": {
        "id": "IQRZrHcS66zw"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialization of weights and biases\n",
        "# Define the first matrix of weights\n",
        "W1 = np.array([[ 0.41687358,  0.08854191, -0.23495225,  0.28320538,  0.41800106],\n",
        "               [ 0.32735501,  0.22795148, -0.23951958,  0.4117634 , -0.23924344],\n",
        "               [ 0.26637602, -0.23846886, -0.37770863, -0.11399446,  0.34008124]])\n",
        "\n",
        "# Define second matrix of weigths\n",
        "W2 = np.array([[-0.22182064, -0.43008631,  0.13310965],\n",
        "               [ 0.08476603,  0.08123194,  0.1772054 ],\n",
        "               [ 0.1871551 , -0.06107263, -0.1790735 ],\n",
        "               [ 0.07055222, -0.02015138,  0.36107434],\n",
        "               [ 0.33480474, -0.39423389, -0.43959196]])\n",
        "\n",
        "# Define first vector of biases\n",
        "b1 = np.array([[ 0.09688219],\n",
        "               [ 0.29239497],\n",
        "               [-0.27364426]])\n",
        "\n",
        "# Define second vector of biases\n",
        "b2 = np.array([[ 0.0352008 ],\n",
        "               [-0.36393384],\n",
        "               [-0.12775555],\n",
        "               [-0.34802326],\n",
        "               [-0.07017815]])"
      ],
      "metadata": {
        "id": "ALx0PmCp7nWx"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'V (vocabulary size): {V}')\n",
        "print(f'N (embedding size / size of the hidden layer): {N}')\n",
        "print(f'size of W1: {W1.shape} (NxV)')\n",
        "print(f'size of b1: {b1.shape} (Nx1)')\n",
        "print(f'size of W2: {W2.shape} (VxN)')\n",
        "print(f'size of b2: {b2.shape} (Vx1)')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Zri1yks82Z8",
        "outputId": "ab6e0b4c-c6a5-40bf-c316-7a8a5d3af520"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "V (vocabulary size): 5\n",
            "N (embedding size / size of the hidden layer): 3\n",
            "size of W1: (3, 5) (NxV)\n",
            "size of b1: (3, 1) (Nx1)\n",
            "size of W2: (5, 3) (VxN)\n",
            "size of b2: (5, 1) (Vx1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the tokenized version of the corpus\n",
        "words = ['i', 'am', 'happy', 'because', 'i', 'am', 'learning']\n",
        "\n",
        "# Get 'word2Ind' and 'Ind2word' dictionaries for the tokenized corpus\n",
        "word2Ind, Ind2word = get_dict(words)\n",
        "\n",
        "# Define the 'get_windows' function\n",
        "def get_windows(words, C):\n",
        "  i = C\n",
        "  while i < len(words) - C:\n",
        "    center_word = words[i]\n",
        "    context_words = words[(i - C) : i] + words[(i + 1) : (i + C + 1)]\n",
        "    yield context_words, center_word\n",
        "    i += 1\n",
        "\n",
        "# Define the 'word_to_one_hot_vector'\n",
        "def word_to_one_hot_vector(word, word2Ind, V):\n",
        "  one_hot_vector = np.zeros(V)\n",
        "  one_hot_vector[word2Ind[word]] = 1\n",
        "  return one_hot_vector\n",
        "\n",
        "# Define the 'context_words_to_vector' function\n",
        "def context_words_to_vector(context_words, word2Ind, V):\n",
        "  context_words_vector = [word_to_one_hot_vector(w, word2Ind, V) for w in context_words]\n",
        "  context_words_vector = np.mean(context_words_vector, axis = 0)\n",
        "  return context_words_vector\n",
        "\n",
        "# Define the generator function 'get_training_examples'\n",
        "def get_training_example(words, C, word2Ind, V):\n",
        "  for context_words, center_word in get_windows(words, C):\n",
        "    yield context_words_to_vector(context_words, word2Ind, V), word_to_one_hot_vector(center_word, word2Ind, V)"
      ],
      "metadata": {
        "id": "D1BOevRg85mK"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save generator object in the 'training_examples' variable with the desired arguments\n",
        "training_examples = get_training_example(words, 2, word2Ind, V)"
      ],
      "metadata": {
        "id": "icGwQxFEAEZb"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the first value from genrator\n",
        "x_array, y_array = next(training_examples)"
      ],
      "metadata": {
        "id": "8jaBkfECAL9h"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the context words vector\n",
        "x_array"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itL2lfBVAQL6",
        "outputId": "72e0d0c4-2562-4ef6-d162-74d03b1fe5e0"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.25, 0.25, 0.  , 0.5 , 0.  ])"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print one hot vector of center word\n",
        "y_array"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tps8jwXkAaKu",
        "outputId": "e1220f22-582e-48b0-e864-917ad638fce0"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 1., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy vector\n",
        "x = x_array.copy()\n",
        "\n",
        "# Reshape it\n",
        "x.shape = (V,1)\n",
        "\n",
        "# Print it\n",
        "print(f'x:\\n{x}\\n')\n",
        "\n",
        "# Copy vector\n",
        "y = y_array.copy()\n",
        "\n",
        "# Reshape it\n",
        "y.shape = (V,1)\n",
        "\n",
        "# Print it\n",
        "print(f'y:\\n{y}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCMR6XUPAe1G",
        "outputId": "dc211a1f-b6cd-45d2-aa1c-9f8924049d57"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x:\n",
            "[[0.25]\n",
            " [0.25]\n",
            " [0.  ]\n",
            " [0.5 ]\n",
            " [0.  ]]\n",
            "\n",
            "y:\n",
            "[[0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the \"relu\" function\n",
        "def relu(z):\n",
        "  result = z.copy()\n",
        "  result[result < 0] = 0\n",
        "  return result\n",
        "\n",
        "# Define softmax function\n",
        "def softmax(z):\n",
        "  e_z = np.exp(z)\n",
        "  sum_e_z = np.sum(e_z)\n",
        "  return e_z / sum_e_z"
      ],
      "metadata": {
        "id": "xoDg_sgADUxU"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Value of the hidden layer\n",
        "# Compute z1 value (value of first hidden layer)\n",
        "z1 = np.dot(W1, x) + b1"
      ],
      "metadata": {
        "id": "Rq7lKxB0Dnue"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print z1\n",
        "z1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xotmqvQSEkW6",
        "outputId": "546af078-1c06-4681-e8ac-57932b10b38f"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.36483875],\n",
              "       [ 0.63710329],\n",
              "       [-0.3236647 ]])"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute h (z1 after applying ReLU function)\n",
        "h = relu(z1)\n",
        "\n",
        "# print h\n",
        "h"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ROfo-A2FDdk",
        "outputId": "da44f217-ff2c-40d6-ccba-7c446fcbe36b"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.36483875],\n",
              "       [0.63710329],\n",
              "       [0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Value of the output layer\n",
        "z2 = np.dot(W2, h) + b2\n",
        "\n",
        "# Print z2\n",
        "z2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AuJ01F9qFKos",
        "outputId": "674d200d-3693-46bb-c3a2-aa339f7a1d4c"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.31973737],\n",
              "       [-0.28125477],\n",
              "       [-0.09838369],\n",
              "       [-0.33512159],\n",
              "       [-0.19919612]])"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute y_hat\n",
        "y_hat = softmax(z2)\n",
        "\n",
        "# Print y_hat prediction\n",
        "y_hat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jx2gPrY8Fm8-",
        "outputId": "57c15a90-7bf3-47c3-aa1c-e613ba8c8c19"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.18519074],\n",
              "       [0.19245626],\n",
              "       [0.23107446],\n",
              "       [0.18236353],\n",
              "       [0.20891502]])"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print target value\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2CcplUgOFtwO",
        "outputId": "2a9a4310-6075-4206-c944-a2e8e6f70f83"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cross-entropy loss"
      ],
      "metadata": {
        "id": "hK4SLcAwG7_G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cross_entropy_loss(y_predicted, y_actual):\n",
        "  loss = -np.sum(y_actual * np.log(y_predicted))\n",
        "  return loss"
      ],
      "metadata": {
        "id": "mfLhIaKCF1vb"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print value of cross entropy loss for prediction and target value\n",
        "cross_entropy_loss(y_hat, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_T4akWHGSDu",
        "outputId": "a7dc5da2-f692-4dcb-f3fe-cf29f687e003"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.4650152923611106"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Backpropagation"
      ],
      "metadata": {
        "id": "WXsW2QpuHGv_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Backpropagation\n",
        "# Compute vector with partial derivatives of loss function with respect to b2\n",
        "grad_b2 = y_hat - y\n",
        "\n",
        "# Print this vector\n",
        "grad_b2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x54OmmmeGUeA",
        "outputId": "83cf3c82-26c5-434d-d28a-ae9d9285f3ff"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.18519074],\n",
              "       [ 0.19245626],\n",
              "       [-0.76892554],\n",
              "       [ 0.18236353],\n",
              "       [ 0.20891502]])"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute matrix with partial derivatives of loss function with respect to W2\n",
        "grad_W2 = np.dot(y_hat - y, h.T)\n",
        "\n",
        "# Print matrix\n",
        "grad_W2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRcV8xzwHVEs",
        "outputId": "c2e09e92-6348-4c7f-f0be-2a780c39cf1a"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.06756476,  0.11798563,  0.        ],\n",
              "       [ 0.0702155 ,  0.12261452,  0.        ],\n",
              "       [-0.28053384, -0.48988499,  0.        ],\n",
              "       [ 0.06653328,  0.1161844 ,  0.        ],\n",
              "       [ 0.07622029,  0.13310045,  0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute vector with partial derivatives of loss function with respect to b1\n",
        "grad_b1 = relu(np.dot(W2.T, y_hat - y))\n",
        "\n",
        "# Print vector\n",
        "grad_b1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovpO0jwhHg_O",
        "outputId": "1bcae252-3dc4-4975-a358-30b9ae590119"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        ],\n",
              "       [0.        ],\n",
              "       [0.17045858]])"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute matrix with partial derivatives of loss function with respect to W1\n",
        "grad_W1 = np.dot(relu(np.dot(W2.T, y_hat - y)), x.T)\n",
        "\n",
        "# Print matrix\n",
        "grad_W1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2RFray_xHm2T",
        "outputId": "054ba9fd-2a86-404e-bd41-bb23b8659041"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
              "       [0.04261464, 0.04261464, 0.        , 0.08522929, 0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'V (vocabulary size): {V}')\n",
        "print(f'N (embedding size / size of the hidden layer): {N}')\n",
        "print(f'size of grad_W1: {grad_W1.shape} (NxV)')\n",
        "print(f'size of grad_b1: {grad_b1.shape} (Nx1)')\n",
        "print(f'size of grad_W2: {grad_W2.shape} (VxN)')\n",
        "print(f'size of grad_b2: {grad_b2.shape} (Vx1)')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsptG1oxHqWP",
        "outputId": "0a81af9a-b2f2-4521-9b58-5c2f69c7f3ca"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "V (vocabulary size): 5\n",
            "N (embedding size / size of the hidden layer): 3\n",
            "size of grad_W1: (3, 5) (NxV)\n",
            "size of grad_b1: (3, 1) (Nx1)\n",
            "size of grad_W2: (5, 3) (VxN)\n",
            "size of grad_b2: (5, 1) (Vx1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gradient descent"
      ],
      "metadata": {
        "id": "NxLHk9cKHsod"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define alpha\n",
        "alpha = 0.03"
      ],
      "metadata": {
        "id": "r3o-JSpAHsAE"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute updated W1\n",
        "W1_new = W1 - alpha * grad_W1"
      ],
      "metadata": {
        "id": "LJdojA56Hy2M"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('old value of W1:')\n",
        "print(W1)\n",
        "print()\n",
        "print('new value of W1:')\n",
        "print(W1_new)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UN2KJvvBNX_M",
        "outputId": "48588a33-73a0-45cd-af29-d44d8d5a833c"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "old value of W1:\n",
            "[[ 0.41687358  0.08854191 -0.23495225  0.28320538  0.41800106]\n",
            " [ 0.32735501  0.22795148 -0.23951958  0.4117634  -0.23924344]\n",
            " [ 0.26637602 -0.23846886 -0.37770863 -0.11399446  0.34008124]]\n",
            "\n",
            "new value of W1:\n",
            "[[ 0.41687358  0.08854191 -0.23495225  0.28320538  0.41800106]\n",
            " [ 0.32735501  0.22795148 -0.23951958  0.4117634  -0.23924344]\n",
            " [ 0.26509758 -0.2397473  -0.37770863 -0.11655134  0.34008124]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute updated W2\n",
        "W2_new = W2 - alpha * grad_W2\n",
        "\n",
        "# Compute updated b1\n",
        "b1_new = b1 - alpha * grad_b1\n",
        "\n",
        "# Compute updated b2\n",
        "b2_new = b2 - alpha * grad_b2\n",
        "\n",
        "\n",
        "print('W2_new')\n",
        "print(W2_new)\n",
        "print()\n",
        "print('b1_new')\n",
        "print(b1_new)\n",
        "print()\n",
        "print('b2_new')\n",
        "print(b2_new)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17edkXkbNe1S",
        "outputId": "ada1ad40-392b-401c-b335-25abf9be4349"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W2_new\n",
            "[[-0.22384758 -0.43362588  0.13310965]\n",
            " [ 0.08265956  0.0775535   0.1772054 ]\n",
            " [ 0.19557112 -0.04637608 -0.1790735 ]\n",
            " [ 0.06855622 -0.02363691  0.36107434]\n",
            " [ 0.33251813 -0.3982269  -0.43959196]]\n",
            "\n",
            "b1_new\n",
            "[[ 0.09688219]\n",
            " [ 0.29239497]\n",
            " [-0.27875802]]\n",
            "\n",
            "b2_new\n",
            "[[ 0.02964508]\n",
            " [-0.36970753]\n",
            " [-0.10468778]\n",
            " [-0.35349417]\n",
            " [-0.0764456 ]]\n"
          ]
        }
      ]
    }
  ]
}