{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNJEYquwxx0HlabIJmh0JQh"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QlzN_J7t0WUk",
        "outputId": "33cf62f3-452a-4ad9-a816-fe89930b1f85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.data.path.append('.')"
      ],
      "metadata": {
        "id": "Lh1bjHj80oWS"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/yeesem/NLP_Dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nRZvVpU2fVY",
        "outputId": "ae20bef5-f8a5-4852-c566-b5edab4be2ab"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'NLP_Dataset'...\n",
            "remote: Enumerating objects: 36, done.\u001b[K\n",
            "remote: Counting objects: 100% (36/36), done.\u001b[K\n",
            "remote: Compressing objects: 100% (36/36), done.\u001b[K\n",
            "remote: Total 36 (delta 7), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (36/36), 21.40 MiB | 4.77 MiB/s, done.\n",
            "Resolving deltas: 100% (7/7), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load, tokenize and process the data\n",
        "import re\n",
        "with open(\"/content/NLP_Dataset/shakespeare.txt\") as f:\n",
        "  data = f.read()\n",
        "\n",
        "data = re.sub(r'[,!?;-]', '.',data)\n",
        "data = nltk.word_tokenize(data)\n",
        "data = [ch.lower() for ch in data if ch.isalpha() or ch == '.']\n",
        "print(\"Number of tokens : \", len(data), \"\\n\", data[:15])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PtPHI51U1Tfp",
        "outputId": "30f499b8-6f97-4618-c057-aad4f536e6e4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of tokens :  60976 \n",
            " ['o', 'for', 'a', 'muse', 'of', 'fire', '.', 'that', 'would', 'ascend', 'the', 'brightest', 'heaven', 'of', 'invention']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the frequency distribution of the words in the dataset\n",
        "fdist = nltk.FreqDist(word for word in data)\n",
        "print(\"Size of vocabulary: \", len(fdist))\n",
        "print(\"Most of frequent tokens : \", fdist.most_common(20))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjLo_tKu2HMQ",
        "outputId": "df2db825-0ddc-4b10-ada3-97911f713eb4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of vocabulary:  5775\n",
            "Most of frequent tokens :  [('.', 9630), ('the', 1521), ('and', 1394), ('i', 1257), ('to', 1159), ('of', 1093), ('my', 857), ('that', 781), ('in', 770), ('a', 752), ('you', 748), ('is', 630), ('not', 559), ('for', 467), ('it', 460), ('with', 441), ('his', 434), ('but', 417), ('me', 417), ('your', 397)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dict(data):\n",
        "  data = sorted(list(set(data)))\n",
        "  word2Ind = {}\n",
        "  Ind2word = {}\n",
        "  idx = 0\n",
        "  for word in data:\n",
        "    word2Ind[word] = idx\n",
        "    Ind2word[idx] = word\n",
        "    idx += 1\n",
        "  return word2Ind, Ind2word"
      ],
      "metadata": {
        "id": "rSt0NY4Q2_Yx"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word2Ind, Ind2word = get_dict(data)\n",
        "V = len(word2Ind)\n",
        "print(\"Size of vocabulary: \", V)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aOC0qSBc3TNG",
        "outputId": "c2196e26-abb0-4080-ac52-6b080f6681a1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of vocabulary:  5775\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of word to index mapping\n",
        "print(\"Index of the word 'king' : \", word2Ind['king'])\n",
        "print(\"Word which has index 2743 : \", Ind2word[2743])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3vbjrds3taB",
        "outputId": "8f4d5275-d484-4852-ee9e-69d60df7ccf7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index of the word 'king' :  2744\n",
            "Word which has index 2743 :  kinds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the Model"
      ],
      "metadata": {
        "id": "X0NGmhCN3-8h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initializing the model"
      ],
      "metadata": {
        "id": "26tpRgXA4Bgv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_model(N, V, random_seed = 1):\n",
        "  np.random.seed(random_seed)\n",
        "\n",
        "  W1 = np.random.uniform(0,1,(N,V))\n",
        "  W2 = np.random.uniform(0,1,(V,N))\n",
        "  b1 = np.random.uniform(0,1,(N,1))\n",
        "  b2 = np.random.uniform(0,1,(V,1))\n",
        "\n",
        "  return W1, W2, b1, b2"
      ],
      "metadata": {
        "id": "xcPjKelf4BLW"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Activation function"
      ],
      "metadata": {
        "id": "puCFBMJa4gdq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax(z):\n",
        "  yhat = np.exp(z) / np.sum(np.exp(z), axis = 0)\n",
        "  return yhat"
      ],
      "metadata": {
        "id": "iXyNPYl9370m"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Forward propagation"
      ],
      "metadata": {
        "id": "OlZiusFq4vAA"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "exCyQgMD4rU2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}