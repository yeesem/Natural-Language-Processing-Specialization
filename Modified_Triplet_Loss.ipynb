{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNJw8uuQqy05A0efXcINYHJ"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ],
      "metadata": {
        "id": "_-Awx2Hdubxu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "eiXJYu9mZLDP"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Similarity Scores"
      ],
      "metadata": {
        "id": "5UY8bWy6dd0w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Two vector example\n",
        "# Input data\n",
        "v1 = np.array([1, 2, 3], dtype = float)\n",
        "v2 = np.array([1, 2, 3.5], dtype = float)\n",
        "\n",
        "# Try modifying the vector v2 to see how it impacts the cosine similarity\n",
        "# v2 = v1                   # identical vector\n",
        "# v2 = v1 * -1              # opposite vector\n",
        "# v2 = np.array([0,-42,1], dtype=float)  # random example\n",
        "\n",
        "print(\"-- Input --\")\n",
        "print(\"V1 : \", v1)\n",
        "print(\"V2 : \", v2, \"\\n\")\n",
        "\n",
        "def cosine_similarity(v1, v2):\n",
        "  numerator = tf.math.reduce_sum(v1 * v2)\n",
        "  denominator = tf.math.sqrt(tf.math.reduce_sum(v1 * v1) * tf.math.reduce_sum(v2 * v2))\n",
        "  return numerator / denominator\n",
        "\n",
        "print(\"-- Outputs --\")\n",
        "print(\"Cosine similarity : \", cosine_similarity(v1, v2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hRRZxrdwdbGa",
        "outputId": "45e73db7-1c76-4822-bb72-84ca67e54908"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- Input --\n",
            "V1 :  [1. 2. 3.]\n",
            "V2 :  [-1. -2. -3.] \n",
            "\n",
            "-- Outputs --\n",
            "Cosine similarity :  tf.Tensor(-1.0, shape=(), dtype=float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Two Batches of Vectors"
      ],
      "metadata": {
        "id": "nX8Fa6BSfaor"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Two batches of vectors example\n",
        "# Input data\n",
        "\n",
        "\"\"\"\n",
        "v1 :\n",
        "array([[ 1.,  2.,  3.],\n",
        "       [ 9.,  8.,  7.],\n",
        "       [-1., -4., -2.],\n",
        "       [ 1., -7.,  2.]])\n",
        "\"\"\"\n",
        "v1_1 = np.array([1.0, 2.0, 3.0])\n",
        "v1_2 = np.array([9.0, 8.0, 7.0])\n",
        "v1_3 = np.array([-1.0, -4.0, -2.0])\n",
        "v1_4 = np.array([1.0, -7.0, 2.0])\n",
        "v1 = np.vstack([v1_1, v1_2, v1_3, v1_4])\n",
        "\n",
        "\"\"\"\n",
        "v2:\n",
        "array([[ 4.72843251, -0.31416263,  3.0220996 ],\n",
        "       [ 9.20017366,  9.47500835,  7.32925269],\n",
        "       [-5.79729922, -4.17808562, -2.54299621],\n",
        "       [ 3.72376963, -7.63641921,  2.29885007]])\n",
        "\"\"\"\n",
        "v2_1 = v1_1 + np.random.normal(0, 2, 3)  # add some noise to create approximate duplicate\n",
        "v2_2 = v1_2 + np.random.normal(0, 2, 3)\n",
        "v2_3 = v1_3 + np.random.normal(0, 2, 3)\n",
        "v2_4 = v1_4 + np.random.normal(0, 2, 3)\n",
        "v2 = np.vstack([v2_1, v2_2, v2_3, v2_4])\n",
        "\n",
        "print(\"-- Input --\")\n",
        "print(f\"v1 : \\n{v1}\\n\")\n",
        "print(f\"v2 : \\n{v2}\\n\")\n",
        "\n",
        "# Batch sizes must match\n",
        "b = len(v1)\n",
        "print(f\"Batch sizes match : {b == len(v2)}\\n\")\n",
        "\n",
        "# Similarity scores\n",
        "# Option 1 : nested loops and the cosine similarity function\n",
        "sim_1 = np.zeros([b, b])\n",
        "for row in range(0, sim_1.shape[0]):\n",
        "  for col in range(0, sim_1.shape[1]):\n",
        "    sim_1[row,col] = cosine_similarity(v2[row], v1[col]).numpy()\n",
        "\n",
        "print(\"-- Outputs --\")\n",
        "print(\"Option 1 : loop\")\n",
        "print(sim_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jXadNfQ6eJHY",
        "outputId": "a9cba52c-e59d-4f4e-8c6c-0891865eac2d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- Input --\n",
            "v1 : \n",
            "[[ 1.  2.  3.]\n",
            " [ 9.  8.  7.]\n",
            " [-1. -4. -2.]\n",
            " [ 1. -7.  2.]]\n",
            "\n",
            "v2 : \n",
            "[[-2.92852677  1.60778267  3.41559857]\n",
            " [ 6.15808817  7.36827865  5.78058324]\n",
            " [-3.76842578 -2.95374122 -1.0572413 ]\n",
            " [-0.81672465 -6.6080942   3.82946569]]\n",
            "\n",
            "Batch sizes match : True\n",
            "\n",
            "-- Outputs --\n",
            "Option 1 : loop\n",
            "[[ 0.58924083  0.15650085 -0.47197698 -0.20939565]\n",
            " [ 0.91173463  0.99178717 -0.91879297 -0.41108239]\n",
            " [-0.70026323 -0.95094808  0.78761446  0.41055358]\n",
            " [-0.08853597 -0.312278    0.55655378  0.94073422]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Option 2 : vector normalization and dot product\n",
        "def norm(x):\n",
        "  return tf.math.l2_normalize(x, axis = 1) # Use tensorflow built in normalization\n",
        "\n",
        "sim_2 = tf.linalg.matmul(norm(v2), norm(v1), transpose_b = True)\n",
        "\n",
        "print(\"-- Outputs --\")\n",
        "print(\"Option 2 : vector normalization and dot product\")\n",
        "print(sim_2, \"\\n\")\n",
        "\n",
        "# Check\n",
        "print(f\"Outputs are the same : {np.allclose(sim_1, sim_2)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJlssxyggLJz",
        "outputId": "20fa46e8-96ad-4e6a-fc58-bb572d7c4f39"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- Outputs --\n",
            "Option 2 : vector normalization and dot product\n",
            "tf.Tensor(\n",
            "[[ 0.58924083  0.15650085 -0.47197698 -0.20939565]\n",
            " [ 0.91173463  0.99178717 -0.91879297 -0.41108239]\n",
            " [-0.70026323 -0.95094808  0.78761446  0.41055358]\n",
            " [-0.08853597 -0.312278    0.55655378  0.94073422]], shape=(4, 4), dtype=float64) \n",
            "\n",
            "Outputs are the same : True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hard Negative Mining\n",
        "L1=max(ùëöùëíùëéùëõ_ùëõùëíùëî‚àís(ùê¥,ùëÉ)+ùõº,0)\n",
        "\n",
        "L2=max(ùëêùëôùëúùë†ùëíùë†ùë°_ùëõùëíùëî‚àís(ùê¥,ùëÉ)+ùõº,0)"
      ],
      "metadata": {
        "id": "aqf9suVVlC0V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hardcoded matrix of similarity scores\n",
        "sim_hardcoded = np.array(\n",
        "    [\n",
        "        [0.9, -0.8, 0.3, -0.5],\n",
        "        [-0.4, 0.5, 0.1, -0.1],\n",
        "        [0.3, 0.1, -0.4, -0.8],\n",
        "        [-0.5, -0.2, -0.7, 0.5],\n",
        "    ]\n",
        ")\n",
        "\n",
        "sim = sim_hardcoded\n",
        "\n",
        "# Try using different values for the matrix of similarity scores\n",
        "# sim = 2 * np.random.random_sample((b,b)) -1   # random similarity scores between -1 and 1\n",
        "# sim = sim_2\n",
        "\n",
        "# Batch size, b = 4\n",
        "b = sim.shape[0]\n",
        "\n",
        "print(\"-- Inputs --\")\n",
        "print(f\"sim:\")\n",
        "print(sim)\n",
        "print(f\"shape: {sim.shape}\\n\")\n",
        "\n",
        "# Positives\n",
        "# All the s(A,P) values : similarities from duplicate question pairs\n",
        "# These are along the diagonal\n",
        "sim_ap = np.diag(sim)\n",
        "print(\"sim_ap : \")\n",
        "print(np.diag(sim_ap))\n",
        "\n",
        "# Negatives\n",
        "# all the s(A,N) values : similarities the non duplicate question pairs (aka Negatives)\n",
        "# There are in the off diagonals\n",
        "sim_an = sim - np.diag(sim_ap)\n",
        "print(\"\\nsim_an : \")\n",
        "print(sim_an)\n",
        "\n",
        "print(\"\\n-- Outputs --\")\n",
        "# Mean negative\n",
        "# Average of the s(A,N) values for each row\n",
        "mean_neg = np.sum(sim_an, axis = 1, keepdims = True)/ (b - 1)\n",
        "print(\"\\nmean_neg: \")\n",
        "print(mean_neg)\n",
        "\n",
        "# Closest negative\n",
        "# Max s(A,N) that is <= s(A,P) for each row\n",
        "\"\"\"\n",
        "np.identity(b): This creates a b√ób identity matrix, where b is presumably the size of your square matrix.\n",
        "An identity matrix has ones on its diagonal and zeros elsewhere.\n",
        "array([[ True, False, False, False],\n",
        "       [False,  True, False, False],\n",
        "       [False, False,  True, False],\n",
        "       [False, False, False,  True]])\n",
        "\"\"\"\n",
        "mask_1 = np.identity(b) == 1            # mask to exclude the diagonal\n",
        "\n",
        "\"\"\"\n",
        "sim_an :\n",
        "[[ 0.  -0.8  0.3 -0.5]\n",
        " [-0.4  0.   0.1 -0.1]\n",
        " [ 0.3  0.1  0.  -0.8]\n",
        " [-0.5 -0.2 -0.7  0. ]]\n",
        "sim_ap :\n",
        "[ 0.9  0.5 -0.4  0.5]\n",
        "sim_ap.reshape(b, 1) :\n",
        "[[ 0.9]\n",
        " [ 0.5]\n",
        " [-0.4]\n",
        " [ 0.5]\n",
        "sim_an > sim_ap.reshape(b, 1) :\n",
        "array([[False, False, False, False],\n",
        "       [False, False, False, False],\n",
        "       [ True,  True,  True, False],\n",
        "       [False, False, False, False]])\n",
        "\"\"\"\n",
        "mask_2 = sim_an > sim_ap.reshape(b, 1)  # mask to exclude sim_an > sim_ap\n",
        "\"\"\"\n",
        "mask_1 | mask_2: This performs an element-wise logical OR operation between mask_1 and mask_2\n",
        "array([[ True, False, False, False],\n",
        "       [False,  True, False, False],\n",
        "       [ True,  True,  True, False],\n",
        "       [False, False, False,  True]])\n",
        "\"\"\"\n",
        "mask = mask_1 | mask_2\n",
        "# create a copy to preserve sim_an\n",
        "sim_an_masked = np.copy(sim_an)\n",
        "# This indexing operation selects the elements in sim_an_masked where mask is True to -2\n",
        "sim_an_masked[mask] = -2\n",
        "\n",
        "closest_neg = np.max(sim_an_masked, axis = 1, keepdims = True)\n",
        "print(\"\\nClosest_neg : \")\n",
        "print(closest_neg)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOQdjbMolFGz",
        "outputId": "dcc60b5e-00b6-4ec5-ea57-2701b47857a7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- Inputs --\n",
            "sim:\n",
            "[[ 0.9 -0.8  0.3 -0.5]\n",
            " [-0.4  0.5  0.1 -0.1]\n",
            " [ 0.3  0.1 -0.4 -0.8]\n",
            " [-0.5 -0.2 -0.7  0.5]]\n",
            "shape: (4, 4)\n",
            "\n",
            "sim_ap : \n",
            "[[ 0.9  0.   0.   0. ]\n",
            " [ 0.   0.5  0.   0. ]\n",
            " [ 0.   0.  -0.4  0. ]\n",
            " [ 0.   0.   0.   0.5]]\n",
            "\n",
            "sim_an : \n",
            "[[ 0.  -0.8  0.3 -0.5]\n",
            " [-0.4  0.   0.1 -0.1]\n",
            " [ 0.3  0.1  0.  -0.8]\n",
            " [-0.5 -0.2 -0.7  0. ]]\n",
            "\n",
            "-- Outputs --\n",
            "\n",
            "mean_neg: \n",
            "[[-0.33333333]\n",
            " [-0.13333333]\n",
            " [-0.13333333]\n",
            " [-0.46666667]]\n",
            "\n",
            "Closest_neg : \n",
            "[[ 0.3]\n",
            " [ 0.1]\n",
            " [-0.8]\n",
            " [-0.2]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# implementation in TensorFlow\n",
        "# Hardcoded matrix of similarity scores\n",
        "sim_hardcoded = np.array(\n",
        "    [\n",
        "        [0.9, -0.8, 0.3, -0.5],\n",
        "        [-0.4, 0.5, 0.1, -0.1],\n",
        "        [0.3, 0.1, -0.4, -0.8],\n",
        "        [-0.5, -0.2, -0.7, 0.5],\n",
        "    ]\n",
        ")\n",
        "\n",
        "sim = sim_hardcoded\n",
        "\n",
        "# Try using different values for the matrix of similarity scores\n",
        "# sim = 2 * np.random.random_sample((b,b)) -1   # random similarity scores between -1 and 1\n",
        "# sim = sim_2                                   # the matrix calculated previously using vector normalization and dot product\n",
        "\n",
        "# Batch size\n",
        "b = sim.shape[0]\n",
        "\n",
        "print(\"-- Inputs --\")\n",
        "print(\"sim :\")\n",
        "print(sim)\n",
        "print(\"shape :\", sim.shape, \"\\n\")\n",
        "\n",
        "# Positives\n",
        "# All the s(A,P) values : similarities from duplicate question pairs (aka Positives)\n",
        "# These are along the diagonal\n",
        "sim_ap = tf.linalg.diag_part(sim) # this is just a 1D array of diagonal elements\n",
        "print(\"sim_ap :\")\n",
        "# tf.linalg.diag makes a diagonal matrix given an array\n",
        "print(tf.linalg.diag(sim_ap), \"\\n\")\n",
        "\n",
        "# Negatives\n",
        "# all the s(A,N) values : similarities the non duplicate question pairs (aka Negatives)\n",
        "# These are in the off diagonals\n",
        "sim_an = sim - tf.linalg.diag(sim_ap)\n",
        "print(\"sim_an :\")\n",
        "print(sim_an, \"\\n\")\n",
        "\n",
        "print(\"-- Outputs --\")\n",
        "# Mean negative\n",
        "# Average of the s(A,N) values for each row\n",
        "mean_neg = tf.math.reduce_sum(sim_an, axis=1) / (b - 1)\n",
        "print(\"mean_neg :\")\n",
        "print(mean_neg, \"\\n\")\n",
        "\n",
        "# Closest negative\n",
        "# Max s(A,N) that is <= s(A,P) for each row\n",
        "mask_1 = tf.eye(b) == 1            # mask to exclude the diagonal\n",
        "mask_2 = sim_an > tf.expand_dims(sim_ap, 1)  # mask to exclude sim_an > sim_ap\n",
        "mask = tf.cast(mask_1 | mask_2, tf.float64)\n",
        "sim_an_masked = sim_an - 2.0*mask\n",
        "\n",
        "closest_neg = tf.math.reduce_max(sim_an_masked, axis=1)\n",
        "print(\"closest_neg :\")\n",
        "print(closest_neg, \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XbmYjn31oj34",
        "outputId": "ca26cdec-beab-439c-ece9-f66e72cffeb0"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- Inputs --\n",
            "sim :\n",
            "[[ 0.9 -0.8  0.3 -0.5]\n",
            " [-0.4  0.5  0.1 -0.1]\n",
            " [ 0.3  0.1 -0.4 -0.8]\n",
            " [-0.5 -0.2 -0.7  0.5]]\n",
            "shape : (4, 4) \n",
            "\n",
            "sim_ap :\n",
            "tf.Tensor(\n",
            "[[ 0.9  0.   0.   0. ]\n",
            " [ 0.   0.5  0.   0. ]\n",
            " [ 0.   0.  -0.4  0. ]\n",
            " [ 0.   0.   0.   0.5]], shape=(4, 4), dtype=float64) \n",
            "\n",
            "sim_an :\n",
            "tf.Tensor(\n",
            "[[ 0.  -0.8  0.3 -0.5]\n",
            " [-0.4  0.   0.1 -0.1]\n",
            " [ 0.3  0.1  0.  -0.8]\n",
            " [-0.5 -0.2 -0.7  0. ]], shape=(4, 4), dtype=float64) \n",
            "\n",
            "-- Outputs --\n",
            "mean_neg :\n",
            "tf.Tensor([-0.33333333 -0.13333333 -0.13333333 -0.46666667], shape=(4,), dtype=float64) \n",
            "\n",
            "closest_neg :\n",
            "tf.Tensor([ 0.3  0.1 -0.8 -0.2], shape=(4,), dtype=float64) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The Loss Functions\n",
        "L1=max(ùëöùëíùëéùëõ_ùëõùëíùëî‚àís(ùê¥,ùëÉ)+ùõº,0)\n",
        "\n",
        "L2=max(ùëêùëôùëúùë†ùëíùë†ùë°_ùëõùëíùëî‚àís(ùê¥,ùëÉ)+ùõº,0)\n",
        "\n",
        "L_Full=L1+L2"
      ],
      "metadata": {
        "id": "LLYG8QoPtH6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Alpha margin\n",
        "alpha = 0.25\n",
        "\n",
        "# Modified triplet loss\n",
        "# Loss 1\n",
        "l_1 = tf.maximum(mean_neg - sim_ap + alpha, 0)\n",
        "print(f\"Loss 1: \\n{l_1}\\n\")\n",
        "# Loss 2\n",
        "l_2 = tf.maximum(closest_neg - sim_ap + alpha, 0)\n",
        "print(f\"Loss 2: \\n{l_2}\\n\")\n",
        "# Loss full\n",
        "l_full = l_1 + l_2\n",
        "# Cost\n",
        "cost = tf.math.reduce_sum(l_full)\n",
        "\n",
        "print(\"-- Outputs --\")\n",
        "print(\"Loss full :\")\n",
        "print(l_full, \"\\n\")\n",
        "print(\"Cost :\", \"{:.3f}\".format(cost))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8SNyGzjso36",
        "outputId": "b854a1bf-d477-4047-d5dd-2fd5ee0b66b3"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss 1: \n",
            "[[0.         0.         0.31666667 0.        ]\n",
            " [0.         0.         0.51666667 0.        ]\n",
            " [0.         0.         0.51666667 0.        ]\n",
            " [0.         0.         0.18333333 0.        ]]\n",
            "\n",
            "Loss 2: \n",
            "[[0.   0.05 0.95 0.05]\n",
            " [0.   0.   0.75 0.  ]\n",
            " [0.   0.   0.   0.  ]\n",
            " [0.   0.   0.45 0.  ]]\n",
            "\n",
            "-- Outputs --\n",
            "Loss full :\n",
            "tf.Tensor(\n",
            "[[0.         0.05       1.26666667 0.05      ]\n",
            " [0.         0.         1.26666667 0.        ]\n",
            " [0.         0.         0.51666667 0.        ]\n",
            " [0.         0.         0.63333333 0.        ]], shape=(4, 4), dtype=float64) \n",
            "\n",
            "Cost : 3.783\n"
          ]
        }
      ]
    }
  ]
}